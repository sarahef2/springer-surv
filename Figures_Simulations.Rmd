---
title: "Random Forests for Survival Analysis and High-Dimensional Data: Figures and Simulations"
author: "Sarah Formentini, Yifan Cui, and Ruoqing Zhu"
date: "Last Updated: `r format(Sys.time(), '%B %d, %Y')`"
abstract: "This is one of the two supplementary `R` files for Random Forests for Survival Analysis and High-Dimensional Data in Springer Handbook of Engineering Statistics."
output: html_document
bibliography: ExFig_bib.bib
---

```{r setup, include=FALSE}
  knitr::opts_chunk$set(echo = TRUE)
  library(survival)
  library(ggplot2)
  library(reshape2)
  library(RLT)
  library(MASS)

```

# Setup  
## Install RLT from GitHub
```{r, eval=FALSE}
  #Installing RLT
  library(devtools)
  install_github("teazrq/RLT")
  library(RLT)
```
  
# Figures and Simulations  
## Proportional hazards demonstration  
Proportional hazards plot. The two exponential distributions Exp(e^1) and Exp(e^2) have proportional hazards. 
```{r}
n<-50
X <- c(rep(exp(1),n),rep(exp(2),n))
Y <- rexp(n,X)
df <- data.frame(X,Y)
df$tm <- c(rep(seq(0,2,length.out = n),2))
df$true <- 1-pexp(df$tm,df$X)

ggplot(df)+geom_line(aes(x=tm,y=true,group=as.factor(X),col=as.factor(X)),size=1.5)+
  scale_color_manual(values=c("darkorange","deepskyblue")) +
    xlab("Time") + 
    ylab("Probability of Survival") + 
    guides(col = guide_legend(title = "X", override.aes = list( shape='')))+
      theme(legend.position = "none",text = element_text(size=20))
ggsave("Results/Prop.png")
```

Next, we generate a non-proportional hazards plot with same expected values, to use in a demonstration. The Beta(5,10) distribution has an expected value of $\frac{5}{10}=\frac{1}{3}$, and the Exp(3) distribution also have an expected value of $\frac{1}{3}$. 
```{r}
library(latex2exp)

n<-50
G1 <- rbeta(n,5,10)
G2 <- rexp(n,3)
X <- c(rep(1,n),rep(0,n))
Dist <- ifelse(X>0.5,"Beta(5,10)","Exp(3)")
T <- c(G1,G2)
C <- runif(n,0.25,1)
Censor <- T<=C
Y <- pmin(T,C)

df <- data.frame(X=as.factor(X),D=as.factor(Dist),Y,Censor)
df$tm <- c(seq(0,1.3,length.out=50),seq(0,1.3,length.out=50))
df$true <- c(1-pbeta(df$tm[X==1],5,10),1-pexp(df$tm[X==1],3))
ggplot(df)+geom_line(aes(x=tm,y=true,group=X,col=X),size=1.5)+
  scale_color_manual(values=c("darkorange","deepskyblue")) +
    xlab("Time") + 
    ylab("Probability of Survival") + 
    guides(col = guide_legend(title = "X", override.aes = list( shape='')))+
      theme(legend.position = "none",text = element_text(size=20))

ggsave("Results/SameExpec.png")
```

## Example tree  
Generating a $p=3$ set of covariates to build a survival tree. Two of the variables are correlated. Data generation choice based on @cui2017consistency.
```{r}
set.seed(472)
X <- mvrnorm(n=1000,mu=c(0,0,0),Sigma=matrix(c(1,0.8,0,0.8,1,0,0,0,1),3,3))
set.seed(473)
T <- rexp(1000,1/exp(-1.25*X[,1]-X[,3]+2))
set.seed(474)
C <- rexp(1000,1/exp(-3*X[,2]+2))
Y <- pmin(T,C)
Censor <- as.numeric(T<=C)

library(rpart)
library(rpart.plot)
library(partykit)

trplt <- function(dat,mdpth=2,typ){
  tr1 <- rpart(Surv(Y,Censor)~.,data=dat,control = list(maxdepth=mdpth))
  tr1b <- rpart(Surv(log(Y+1),Censor)~.,data=dat,control = list(maxdepth=mdpth,cp=0.0001))
  tr2 <- as.party(tr1b)
  sf_all <- survfit(Surv(Y,Censor)~1,data=dat)
  mdpt <- sf_all$time[min(which(sf_all$surv<=0.5))]
  dat$node<-tr1$where
  tr1$frame$dpth <- sapply(as.numeric(rownames(tr1$frame)), function(i){
    floor(log(i)/log(2))
  })
  if(typ==1) prp(tr1,node.fun = function(x, labs, digits, varlen) paste0(tr1$frame$dpth),type = 2) else print(plot(tr2,digits=2,margins=c(1,0.4,0.1,0.4)))

}

rf_data <- data.frame(X,Y,Censor)

tr1 <- rpart(Surv(Y,Censor)~.,data=rf_data,control = list(maxdepth=3))
rf_data$node<-tr1$where
tr1$frame$dpth <- sapply(as.numeric(rownames(tr1$frame)), function(i){
  floor(log(i)/log(2))
})

png("Results/TreeSimDataDpt.png")
prp(tr1,node.fun = function(x, labs, digits, varlen) paste0(tr1$frame$dpth),type = 2)
#trplt(rf_data,3,1)
dev.off()

tr1b <- rpart(Surv(log(Y+1),Censor)~.,data=rf_data,control = list(maxdepth=2,cp=0.0001))
tr2 <- as.party(tr1b)

png("Results/TreeSimData.png",height=300)
plot(tr2,digits=2,margins=c(1,0.4,0.1,0.4))
#trplt(rf_data,2,2)
dev.off()
```
Kosorok-Renyi algorithms (http://mkosorok.web.unc.edu/renyi/)
```{r}
sup.G<-function(x,m=10)
{
     k<-m:0
     (4/pi)*sum(((-1)^k)/(2*k+1)*exp(-(pi^2)*((2*k+1)^2)/(8*x^2)))
}
sup.g<-function(x,m=10)
{
     k<-m:0
     (pi/x^3)*sum(((-1)^k)*(2*k+1)*exp(-(pi^2)*((2*k+1)^2)/(8*x^2)))
}
cnorm<-function(z,thresh=3.6,delta=0.6,kk=4){
check<-F
if(z<0){
     z<-(-1)*z
     check<-T
}
if(z<thresh){
     out<-1-pnorm(z)
}
else{
     term<-1
     tally<-term
     if(kk>1){
          for(k in 1:(kk-1)){
               term<-(-1)*term*(2*k-1)/z^2
               tally<-tally+term
          }
     }
     out<-tally*dnorm(z)/z
     if(z<thresh+delta){
          x<-1-pnorm(z)
          out<-x+(z-thresh)*(out-x)/delta
     }
}
if(check){out<-1-out}
out
}
sup.inverse<-function(alpha,error=1e-8)
{
     x<-qnorm(1-alpha/4)
     temp<-max(1,2/x)
     m<-ceiling((x/pi)*sqrt(2*log(temp/(pi*error)))-0.5)
     if(m<0){m<-0}
     interror<-1
     while(interror>error)
     {
          yx<-sup.G(x,m=m)
          dg<-sup.g(x,m=m)
          delta<-(1-alpha-yx)/dg
          x<-x+delta
          interror<-sup.G(x)-(1-alpha)
     }
     x
}
sup.r<-function(alpha, beta, error=1e-8)
{
     u<-sup.inverse(alpha,error=error)
     y<-1-beta
     ml<-qnorm(1-alpha/2)+qnorm(1-beta)
     x<-ml
     delta<-1
     while(delta>error)
     {
          yx<-cnorm(u-x)+exp(2*x*u)*cnorm(u+x)
          dp<-dnorm(u-x)-exp(2*u*x)*dnorm(u+x)+2*u*exp(2*u*x)*cnorm(u+x)
          delta<-(y-yx)/dp
          x<-x+delta
     }
     (x/ml)^2    
}
surv.Rtest<-function (time, delta, group, rho=0, gamma=0, logrank=F, 
     error=1.0e-8) 
{    
     otime <- order(time)
     time <- time[otime]
     delta <- delta[otime]
     n<-length(time)
     if((rho+gamma)==0){
          weight<-rep(1,n)
     }
     else{
          km.left<-KM.left(time,delta)
          weight<-km.left^rho*(1-km.left)^gamma
     }
     group <- group[otime] - 1
     n2 <- sum(group)
     atrisk2 <- n2 - cumsum(group) + group
     n1 <- n-n2
     atrisk1 <- n1 - cumsum(1 - group) + 1 - group
     delta1 <- delta * (1 - group)
     delta2 <- delta * group
     y1 <- tapply(atrisk1, time, "max")
     y2 <- tapply(atrisk2, time, "max")
     d1 <- tapply(delta1, time, "sum")
     d2 <- tapply(delta2, time, "sum")
     weight<-tapply(weight,time,"max")
     w <- (y1 * y2)/(y1 + y2)
     terms <- (d1/y1 - d2/y2)[w > 0]
     temp<-y1+y2-1
     temp<-ifelse(temp<1,1,temp)
     cc<-1-(d1+d2-1)/temp
     vterms <- (cc*(d1 + d2)/(y1 + y2))[w > 0]
     weight<-weight[w > 0]
     w <- w[w > 0]
     terms <- (weight * w * terms)/sqrt(sum(weight^2 * w * vterms))
     temp<-c(0,cumsum(terms))
     xs<-max(temp)
     xi<-min(temp)
     if(abs(xs)>abs(xi)){test<-xs}
     else{test<-xi}
     x <- abs(test)
     m<-ceiling(max(c(1,(x*sqrt(2)/pi)*sqrt(max(c(1,log(1/(pi*error)))))-0.5)))
     p<-1-sup.G(x,m=m)
     out <- NULL
     out$test <- test
     out$p <- p
     if(logrank){
          x<-temp[length(temp)]
          out$test.logrank<-x
          out$p.logrank<-2*cnorm(abs(x))
     }
     out
}
KM.left<-function(time,delta){
     n<-length(time)
     dtime<-tapply(time,time,"max")
     ddelta<-tapply(delta,time,"sum")
     dy<-tapply(rep(1,n),time,"sum")
     m<-length(dy)
     y<-rep(n,m)-c(0,cumsum(dy)[1:(m-1)])
     km<-1
     km.left<-rep(0,m)
     for(i in 1:m){
          km.left[i]<-km
          km<-km*(1-ddelta[i]/y[i])
     }
     out<-rep(0,n)
     for(i in 1:n){
          out[i]<-min(km.left[dtime==time[i]])
     }
     out
}

```

## Splitting rules  
Log-rank and supremum log-rank demonstration calculations.
```{r}
n <- 30
set.seed(123)
G1 <- rbeta(n,5,10)
set.seed(456)
G2 <- rexp(n,3)
X1 <- c(rep(0,n),rep(1,n))
set.seed(12)
X2 <- sample(c(rep(0,n),rep(1,n)),n*2)
T <- c(G1,G2)
set.seed(345)
C <- runif(n,0,1)
Censor <- T<=C
Y <- pmin(T,C)

sfitx1 <- survfit(Surv(Y,Censor)~X1)$surv
sftmx1 <- survfit(Surv(Y,Censor)~X1)$time
sfitx2 <- survfit(Surv(Y,Censor)~X2)$surv
sftmx2 <- survfit(Surv(Y,Censor)~X2)$time

timepoints = sort(unique(Y[Censor == 1]))

y.point = rep(NA, length(Y))

for (i in 1:length(Y))
{
  if (Censor[i] == 1)
    y.point[i] = match(Y[i], timepoints)
  else
    y.point[i] = sum(Y[i] >= timepoints)
}
lrx1 <- numeric(length(timepoints))
lfx1 <- numeric(length(timepoints))
lrx2 <- numeric(length(timepoints))
lfx2 <- numeric(length(timepoints))
ar <- numeric(length(timepoints))
af <- numeric(length(timepoints))
for (i in 1:length(Y))
{
  if (X1[i] == 0){
    lfx1[y.point[i]]<-lfx1[y.point[i]]+Censor[i]
    for(j in 1:y.point[i]) lrx1[j]<-lrx1[j]+1
  }
  if (X2[i] == 0){
    lfx2[y.point[i]]<-lfx2[y.point[i]]+Censor[i]
    for(j in 1:y.point[i]) lrx2[j]<-lrx2[j]+1
  }
  af[y.point[i]]<-af[y.point[i]]+Censor[i]
  for(j in 1:y.point[i]) ar[j]<-ar[j]+1
}

survdiff(Surv(Y,Censor)~X1)$chisq
survdiff(Surv(Y,Censor)~X1)
suplogrank_stat(lfx1,lrx1,af,ar)
surv.Rtest(Y,Censor,X1+1)
survdiff(Surv(Y,Censor)~X2)$chisq
survdiff(Surv(Y,Censor)~X2)
suplogrank_stat(lfx2,lrx2,af,ar)
surv.Rtest(Y,Censor,X2+1)

plot_framex1 <- data.frame(Time = sftmx1, Survival = sfitx1,
                           C = ifelse(survfit(Surv(Y,Censor)~X1)$n.censor>0,"Censored",NA),
                           Group = as.factor(X1))
plot_framex2 <- data.frame(Time = sftmx2, Survival = sfitx2,
                           C = ifelse(survfit(Surv(Y,Censor)~X2)$n.censor>0,"Censored",NA),
                           Group = as.factor(c(rep(0,survfit(Surv(Y,Censor)~X2)$strata[1]),
                                             rep(1,survfit(Surv(Y,Censor)~X2)$strata[2]))))

  ggplot(plot_framex1,aes(x=Time,y=Survival)) + 
    geom_step(aes(x=Time,y=Survival,col=Group),size=1,show.legend = TRUE) +
    scale_shape_manual(na.translate=FALSE,values="+") +
    geom_point(aes(shape=C,col=Group),size=5,na.rm = TRUE,show.legend = TRUE, position = "jitter") +
    scale_color_manual(values=c("darkorange","deepskyblue")) +
    xlab("Time") + 
    ylab("Probability of Survival") + 
    guides(col = guide_legend(title = TeX("x^{(1)}"), override.aes = list( shape='')), 
           shape = guide_legend(title = "", override.aes = list(linetype = 0)))+
      theme(legend.position = "none",text = element_text(size=20))#+ annotate(geom="text", x=0.7, y=0.8, label=paste0(),color="black")
  
  ggsave("Results/DemoSampleX1.png")
  ggplot(plot_framex2,aes(x=Time,y=Survival)) + 
    geom_step(aes(x=Time,y=Survival,col=Group),size=1,show.legend = TRUE) +
    scale_shape_manual(na.translate=FALSE,values="+") +
    geom_point(aes(shape=C,col=Group),size=5,na.rm = TRUE,show.legend = TRUE, position = "jitter") +
    scale_color_manual(values=c("darkorange","deepskyblue")) +
    xlab("Time") + 
    ylab("Probability of Survival") + 
    guides(col = guide_legend(title = TeX("x^{(2)}"), override.aes = list( shape='')), 
           shape = guide_legend(title = "", override.aes = list(linetype = 0)))+
      theme(legend.position = "none",text = element_text(size=20))
  
  ggsave("Results/DemoSampleX2.png")
```


## Bias Example  
Example based on [@cui2017consistency]
```{r, Cui_Ex,eval=FALSE}
sum_mat <- matrix(0,2,3)

for(i in 1:1000){
  set.seed(10000+i)
  X <- mvrnorm(n=1000,mu=c(0,0,0),Sigma=matrix(c(1,0.8,0,0.8,1,0,0,0,1),3,3))
  set.seed(20000+i)
  T <- rexp(1000,1/exp(-1.25*X[,1]-X[,3]+2))
  set.seed(30000+i)
  C <- rexp(1000,1/exp(2))
  Y <- pmin(T,C)
  Censor <- as.numeric(T<=C)
  fit <- RLT(X,Y,Censor,ntrees = 1,nmin = 100,split.gen = "best",mtry=3,resample.prob = 1)
  sum_mat[1,fit$FittedForest$SplitVar[[1]][1,1]+1]<-sum_mat[1,fit$FittedForest$SplitVar[[1]][1,1]+1]+1 
  set.seed(40000+i)
  C <- rexp(1000,1/exp(-3*X[,2]+2))
  Y <- pmin(T,C)
  Censor <- as.numeric(T<=C)
  fit <- RLT(X,Y,Censor,ntrees = 1,nmin = 100,split.gen = "best",mtry=3,resample.prob = 1)
  sum_mat[2,fit$FittedForest$SplitVar[[1]][1,1]+1]<-sum_mat[2,fit$FittedForest$SplitVar[[1]][1,1]+1]+1 

}
```

```{r,include=FALSE}
#save(sum_mat, file="Data\\BiasDemoResults.Rdata")
load("Data\\BiasDemoResults.Rdata")
```

Results will likely vary slightly due to random number generation between random forest iterations.
```{r}
sum_mat/1000
```

# References